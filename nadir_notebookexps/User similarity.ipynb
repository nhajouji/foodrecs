{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9523bfb5-bea2-490e-9f18-ec3cb20b9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da154a-9fb7-4d35-9669-cc7c5445f352",
   "metadata": {},
   "source": [
    "# User similarity based predictions\n",
    "\n",
    "Our goal in this notebook is to accomplish the following tasks:\n",
    "* Come up with a meaningful way of measuring the similarity between two users\n",
    "* Obtain predictions for unrated items by using the ratings of similar users.\n",
    "using only ratings data.\n",
    "\n",
    "I'm going to use the toy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98760f5d-a0c8-4d33-8103-f47083d8be3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewerId</th>\n",
       "      <th>RecipeLabel</th>\n",
       "      <th>Rating</th>\n",
       "      <th>LabelId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(8629, Easy Vidalia Onion Casserole)</th>\n",
       "      <td>8629</td>\n",
       "      <td>Easy Vidalia Onion Casserole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4470, Veggie Soup)</th>\n",
       "      <td>4470</td>\n",
       "      <td>Veggie Soup</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(6357, Mango Daiquiri)</th>\n",
       "      <td>6357</td>\n",
       "      <td>Mango Daiquiri</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(6357, Butter Chicken)</th>\n",
       "      <td>6357</td>\n",
       "      <td>Butter Chicken</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(6357, Baklava)</th>\n",
       "      <td>6357</td>\n",
       "      <td>Baklava</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ReviewerId  \\\n",
       "Pair                                               \n",
       "(8629, Easy Vidalia Onion Casserole)        8629   \n",
       "(4470, Veggie Soup)                         4470   \n",
       "(6357, Mango Daiquiri)                      6357   \n",
       "(6357, Butter Chicken)                      6357   \n",
       "(6357, Baklava)                             6357   \n",
       "\n",
       "                                                       RecipeLabel  Rating  \\\n",
       "Pair                                                                         \n",
       "(8629, Easy Vidalia Onion Casserole)  Easy Vidalia Onion Casserole     4.0   \n",
       "(4470, Veggie Soup)                                    Veggie Soup     5.0   \n",
       "(6357, Mango Daiquiri)                              Mango Daiquiri     4.0   \n",
       "(6357, Butter Chicken)                              Butter Chicken     4.0   \n",
       "(6357, Baklava)                                            Baklava     3.0   \n",
       "\n",
       "                                      LabelId  \n",
       "Pair                                           \n",
       "(8629, Easy Vidalia Onion Casserole)     4741  \n",
       "(4470, Veggie Soup)                      4450  \n",
       "(6357, Mango Daiquiri)                   2577  \n",
       "(6357, Butter Chicken)                   2560  \n",
       "(6357, Baklava)                          4245  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minidf = pd.read_pickle('../data/authlabrat.pk')\n",
    "minidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9c95b9-b444-45fd-99bc-398c8b1858b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = minidf.ReviewerId.unique()\n",
    "recipe_labels = minidf.RecipeLabel.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e5e79-58a9-41e3-b046-7c355cb7d202",
   "metadata": {},
   "source": [
    "We're going to represent \"ratings vectors\" (the rows in the ratings matrix) as dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "949a771d-3f1d-422a-b000-c224953fce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries(ratingsdf,usercol,itemcol,ratingcol):\n",
    "    users = list(set(ratingsdf[usercol].values))\n",
    "    items = list(set(ratingsdf[itemcol].values))\n",
    "    ratings_by_user = {user_id:{} for user_id in users}\n",
    "    users_by_item = {item_id:[] for item_id in items}\n",
    "    for review_index in ratingsdf.index:\n",
    "        user_id = ratingsdf[usercol][review_index]\n",
    "        item_id = ratingsdf[itemcol][review_index]\n",
    "        rating = ratingsdf[ratingcol][review_index]\n",
    "        ratings_by_user[user_id][item_id] = rating\n",
    "        users_by_item[item_id].append(user_id)\n",
    "    return ratings_by_user,users_by_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2dee6-cad9-441e-9377-d2f8bcd5da09",
   "metadata": {},
   "source": [
    "When we make predictions on our test set, we should only use ratings from the training set.\n",
    "\n",
    "Thus, we do our train test split now and then compute the ratings vectors using only reviews in the training set.\n",
    "\n",
    "However, we have to do this carefully - in order to make predictions for a user-item pair in the holdout set, we will need that user and that item to have appeared in a different pair in the training set. We can ensure that every user appears in the training set by stratifying the sampling using the user column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba4c4833-e970-47c0-82bf-a63064be6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ee12276-b768-44b9-8245-103e357b9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratdf_train, ratdf_test = train_test_split(minidf,test_size=0.2, random_state=1729,stratify = minidf.ReviewerId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eabe6674-6f82-40e8-9b3e-80af4a8c08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_by_author,reviewers_by_recipe = get_dictionaries(ratdf_train,'ReviewerId','RecipeLabel','Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a665e9a-3f29-4f3c-9fdf-2e292b18ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_in_training = list(reviewers_by_recipe.keys())\n",
    "mean_ratings_train = {author_id:np.mean(list(ratings_by_author[author_id].values()))\n",
    "                      for author_id in ratings_by_author}\n",
    "std_ratings_train = {author_id:np.std(list(ratings_by_author[author_id].values()))\n",
    "                      for author_id in ratings_by_author}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26631cb2-81b5-4733-bc5b-2c87f64c2892",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratdf_test_ext['MeanRatingTrain'] = [mean_ratings_train[author_id] for author_id in ratdf_test_ext.ReviewerId]\n",
    "ratdf_test_ext['StdRatingTrain'] = [std_ratings_train[author_id] for author_id in ratdf_test_ext.ReviewerId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9de1a372-06f1-46c0-af77-2442c24ad419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    value = data[0]\n",
    "    mean = data[1]\n",
    "    std = data[2]\n",
    "    if std == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (value-mean)/std\n",
    "\n",
    "ratdf_test_ext['Normalized_Ratings']= [normalize(data) for data in ratdf_test_ext[['Rating','MeanRatingTrain','StdRatingTrain']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d0a50-ca00-4a5c-a5c8-631cbccc9612",
   "metadata": {},
   "source": [
    "Note that not every recipe appears in the training set; we can deal with this by doing a k-fold split or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60a8c344-35cf-454c-8abd-96c010392169",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_test_not_train = list(set(ratdf_test['RecipeLabel'].values)-set(recipes_in_training))\n",
    "pairs_in_testtrain = [pair for pair in ratdf_test.index if pair[1] not in recs_test_not_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bad12ada-fa4b-4c4b-a4a3-e8981955dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14183\n",
      "14318\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs_in_testtrain))\n",
    "print(len(ratdf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d401497-2423-4d1d-ba12-71eb3bdc4919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Similarity scores\n",
    "Given two such dictionaries that represent user ratings, we will need a way of quantifying how similarly two users rate recipes.\n",
    "\n",
    "* If user1 and user2 have both rated every recipe, or they've rated the exact same set of recipes, we will use the usual formula for cosine similarity:\n",
    "we normalize the ratings so that they have mean 0 and standard deviation 1, and compute the cosine similarity of those vectors.\n",
    "* If user1 and user2 have rated none of the same recipes, we will not assign them a number (we could say 0 but I prefer to say \"No comment\").\n",
    "\n",
    "Now, when two users have some overlap, we will do something that differs slightly from cosine similarity:\n",
    "* First, we normalize the ratings of user1 and user2 so that the average rating is 0 for both when considering ALL recipes rated by each of those respective users.\n",
    "* Then, we drop all recipes that haven't been rated by both authors from consideration. I.e. Let $V$ be the space with basis indexed by all recipes, and let $U$ be the subspace spanned by the recipes that have been rated by user1 and user2. We write $u_1, u_2$ to denote the (normalized) ratings vectors restricted to these subspaces.\n",
    "* We will use the cosine similarity of $u_1, u_2$ as our measure of similarity between user1 and user2.\n",
    "\n",
    "Important distinctions:\n",
    "* I'm not renormalizing $u_1, u_2$ so that they have mean 0. So, it's like I'm doing cosine similarity in $V$.\n",
    "* However, I'm not dividing by the actual length of the vectors in $V$ - I'm using the length of the projection to $U$.\n",
    "\n",
    "Here is why these changes make sense:\n",
    "* Say user1 gave above average scores to all recipes they have in common with user2, but user2 gave them below average scores. Then $u_1 \\cdot u_2$ is going to be negative, and we would like it to be negative, since user1 and user2 clearly have opposite opinions on everything. If we translated $u_1, u_2$ so that they have mean 0, we would get a number that quantifies how user1 and user2 feel about that restricted set of recipes but not how they feel about recipes in general. Therefore, it makes more sense to ensure the global mean rating is 0 and not translate the ratings beyond that.\n",
    "* Now, we could just say we're doing cosine similarity in $V$. The distinction between that and what we're doing is that the lengths of the ratings vectors in $V$ are bigger than the lengths of the ratings vectors in $U$. To see how this might affect things, suppose we have a third user user3. If user3 and user2 have the same overlap with user1, and the same ratings on that overlap, then we would like the similarity score of user1,user2 and user1,user3 to be the same. In particular, it shouldn't matter whether user3 has rated a million other recipes or 5 other recipes. Now, if we use the length in $V$, then users will be penalized for having rated other recipes - this doesn't make sense. So we will use the length of $u_1, u_2$, rather than the length of the original vector in $V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90714404-0ec2-465d-ab78-042a083688b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8772012-7588-4771-8170-23eeab1e8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(ratings1,ratings2):\n",
    "    user1mean = np.mean(list(ratings1.values()))\n",
    "    user2mean = np.mean(list(ratings2.values()))\n",
    "    common_recipes = set(ratings1.keys()).intersection(set(ratings2.keys()))\n",
    "    if len(common_recipes)== 0:\n",
    "        return -2\n",
    "    l1 = 0\n",
    "    l2 = 0\n",
    "    dot = 0\n",
    "    for recipe_id in common_recipes:\n",
    "        r1 = ratings1[recipe_id]-user1mean\n",
    "        r2 = ratings2[recipe_id]-user2mean\n",
    "        l1+=r1**2\n",
    "        l2+=r2**2\n",
    "        dot+=r1*r2\n",
    "    # If the normalized ratings are all 0 for one of the users,\n",
    "    # the corresponding length will be 0. We may as well return 0.\n",
    "    if l1*l2 == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dot/np.sqrt(l1*l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd66b3-b59d-48f9-b426-d14fc69012b8",
   "metadata": {},
   "source": [
    "## Related ratings\n",
    "\n",
    "Given a user and an unranked item (chosen from the testing set), we want to predict the rating using the training data.\n",
    "\n",
    "We will do the following:\n",
    "* First, we obtain a list of the users that have rated the item we're interested in.\n",
    "* Next, we check whether any of those users have rated any of the same items as our user. If there are none, we do not make a prediction.\n",
    "* Otherwise, we will make a prediction based on the ratings given by those users and their similarity to the original user.\n",
    "\n",
    "Before trying to make any predictions, let's just try to collect the necessary data and see how many pairs we are even able to make a prediction for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54701564-b7fa-4875-a926-dc210ccd3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_ratings_info(author_id,recipe_label):\n",
    "    rating_dic = ratings_by_author[author_id]\n",
    "    other_recipes = set(rating_dic.keys())\n",
    "    recipe_reviewers = reviewers_by_recipe[recipe_label]\n",
    "    relevant_data = {}\n",
    "    for author_id1 in recipe_reviewers:\n",
    "        rating_dic1 = ratings_by_author[author_id1]\n",
    "        no_common_recipes = len(set(rating_dic1.keys()).intersection(other_recipes))\n",
    "        if no_common_recipes>0:\n",
    "            simscore = similarity(rating_dic,rating_dic1)\n",
    "            truerating = rating_dic1[recipe_label]\n",
    "            normrating = truerating-np.mean(list(rating_dic1.values()))\n",
    "            if normrating != 0:\n",
    "                normrating = normrating/np.std(list(rating_dic1.values()))\n",
    "            relevant_data[author_id1] = {'Similarity':simscore,\n",
    "                                         'No_common_revs':no_common_recipes,\n",
    "                                         'True_rating':truerating,\n",
    "                                         'Norm_rating':normrating}\n",
    "    return relevant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e72edf86-dd8c-4c89-bc88-1ec4fe3a077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(pair,min_com_revs,min_sim):\n",
    "    author_id = pair[0]\n",
    "    recipe_label = pair[1]\n",
    "    related_user_data = get_related_ratings_info(author_id,recipe_label)\n",
    "    norm_ratings = []\n",
    "    weights_v1 = []\n",
    "    weights_v2 = []\n",
    "    for author2 in related_user_data:\n",
    "        author2_data = related_user_data[author2]\n",
    "        if author2_data['No_common_revs']>= min_com_revs and author2_data['Similarity']>min_sim:\n",
    "            norm_ratings.append(author2_data['Norm_rating'])\n",
    "            weights_v1.append(author2_data['Similarity'])\n",
    "            weights_v2.append(author2_data['No_common_revs']*author2_data['Similarity'])\n",
    "    if len(norm_ratings)>0:\n",
    "        pred1 = np.average(norm_ratings,weights = weights_v1)\n",
    "        pred2 = np.average(norm_ratings,weights = weights_v2)\n",
    "        return [pred1,pred2]\n",
    "    else:\n",
    "        return []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5aa7472-8f6c-4302-bc9b-8d5605cecaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = {pair:get_related_ratings_info(pair[0],pair[1]) for pair in pairs_in_testtrain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b091f3af-3408-457f-991f-3e76b2e6c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_v0 = {pair:make_predictions(pair,2,0.1) for pair in pairs_in_testtrain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e3c01cc-649a-4a36-bf56-49d6a95526e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_norm_ratings = {pair:ratdf_test_ext['Normalized_Ratings'][pair] for pair in ratdf_test_ext.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e81829e0-0165-496f-8458-40c9ce448631",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_v00 = {pair:preds_v0[pair][0] for pair in preds_v0 if len(preds_v0[pair])>0}\n",
    "preds_v01 = {pair:preds_v0[pair][1] for pair in preds_v00}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0bdbb24-e7af-481c-988c-e0b0575f76fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04234526439510109"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(preds_v01,test_true_norm_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c71397-73d4-441b-9722-e536cf66d9e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## End of main\n",
    "\n",
    "Everything below needs to be moved elsewhere or deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "142220b6-8320-4fee-84c8-9b0e4e501ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13454"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_v00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad01e0b1-72a7-4866-8ca2-5062fb71e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9222"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([pair for pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f63f453-3955-408b-9fc1-8bc2ca8c07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_authrec(author_min,recipe_min):\n",
    "    author_ids_new = set([author_id for author_id in author_ids if len(data_by_author[author_id]) >= author_min])\n",
    "    recipe_ids_new = set([recipe_id for recipe_id in recipe_ids \n",
    "                           if len(set(data_by_recipe[recipe_id].keys()).intersection(author_ids_new)) >= recipe_min])\n",
    "    data_by_author_new = {author_id:{recipe_id:data_by_author[author_id][recipe_id] \n",
    "                          for recipe_id in recipe_ids_new.intersection(set(data_by_author[author_id].keys()))}\n",
    "                          for author_id in author_ids_new}\n",
    "    data_by_recipe_new = {recipe_id:{author_id:data_by_recipe[recipe_id][author_id] \n",
    "                          for author_id in author_ids_new.intersection(set(data_by_recipe[recipe_id].keys()))}\n",
    "                          for recipe_id in recipe_ids_new}\n",
    "    return [data_by_author_new,data_by_recipe_new]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a337f3fe-da9c-4438-8950-a78a933f0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dics1 = get_dense_authrec(50,1)\n",
    "data_by_author0 = dics1[0]\n",
    "data_by_recipe0 = dics1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2ecaec8-200b-4819-85be-3f53fc82a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56644a29-ee5f-4153-b9b0-43446772ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matdf = minidf.pivot(index = 'ReviewerId',columns = 'RecipeLabel',values = 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "956a9e74-10f9-4ebc-b74b-0ad210d19c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = list(matdf.index)\n",
    "cols = list(matdf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a8686-d2f5-45a6-aa75-05408cbfea5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
